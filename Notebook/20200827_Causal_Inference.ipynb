{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20200827 サブゼミ　効果検証入門（因果推論）\n",
    "\n",
    "今回は**Post Treatment Bias**を扱う。Post Treatment Biasとは、処置が決まった後に決まる共変量（らしきもの）をモデルに含めた場合に処置効果の推定値に生じるバイアスのことである。\n",
    "\n",
    "今回、サイトの来訪(visit)が問題となる共変量（らしきもの）である。visitはメールの配信という処置の後に決まる変数であり、visitを入れると**処置がたとえランダムに割り当てられていたとしても処置変数のパラメータの推定値にバイアスが生じることが知られている。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!-*-coding:utf-8-*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリ・モジュール群をインポート。`statsmodels`は、scipyのバージョンが古くないと使えないことがある。\n",
    "\n",
    "今回は、scipyを一旦アンインストールして、scipy1.1.0をインストールすることで解決した。コマンドライン上の操作は、\n",
    "\n",
    "`pip uninstall scipy`\n",
    "\n",
    "`pip install scipy=1.1.0`\n",
    "\n",
    "___\n",
    "\n",
    "## データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_df = pd.read_csv(\"./datas/Kevin_Hillstrom_MineThatData_E-MailAnalytics_DataMiningChallenge_2008.03.20 (1).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandasでデータセットをインポート。mail_dfオブジェクトに格納。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 女性向けメールが配信されたデータを削除したデータを作成\n",
    "\n",
    "male_df = mail_df[mail_df.segment != 'Womens E-Mail'].copy()# 女性向けメールが配信されたデータを削除\n",
    "\n",
    "male_df[\"treatment\"] = np.where(male_df.segment ==\"Mens E-Mail\",1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本の設定の通り、女性向けメールが配信されたレコードを削除するクエリを書く(segmentカラムの値がWomens E-mailであるものを削除)。\n",
    "また、処置変数`treatment`を作成。ここでは、Numpyの`where`関数でクエリを書いている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バイアスのあるデータの作成(ここが本では明示的に書かれていなかった。1章のバイアスの作り方を適用)\n",
    "sample_rules = (male_df.history > 300) | (male_df.recency < 6) | (male_df.channel == 'Multichannel')\n",
    "biased_df = pd.concat([\n",
    "    male_df[(sample_rules) & (male_df.treatment == 0)].sample(frac=0.5, random_state=1),\n",
    "    male_df[(sample_rules) & (male_df.treatment == 1)],\n",
    "    male_df[(~sample_rules) & (male_df.treatment == 0)],\n",
    "    male_df[(~sample_rules) & (male_df.treatment == 1)].sample(frac=0.5, random_state=1)\n",
    "], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先週のサブゼミで推定値が本の結果と合わなかったのは、データセットに人工的なバイアスを発生させていなかったため。本では、第１章のデータでのバイアスの発生方法を第２章のデータセットにも適用しているようである。\n",
    "\n",
    "___\n",
    "\n",
    "## 処置変数とvisitの相関"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>    0.7153</td> <td>    0.011</td> <td>   63.968</td> <td> 0.000</td> <td>    0.693</td> <td>    0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>visit</th>         <td>    0.1509</td> <td>    0.008</td> <td>   19.820</td> <td> 0.000</td> <td>    0.136</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recency</th>       <td>   -0.0282</td> <td>    0.001</td> <td>  -35.621</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>history</th>       <td>    0.0001</td> <td> 1.17e-05</td> <td>    9.705</td> <td> 0.000</td> <td> 9.06e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>channel_Phone</th> <td>   -0.0708</td> <td>    0.009</td> <td>   -7.453</td> <td> 0.000</td> <td>   -0.089</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>channel_Web</th>   <td>   -0.0771</td> <td>    0.009</td> <td>   -8.131</td> <td> 0.000</td> <td>   -0.096</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Zとvisitの相関\n",
    "Y = biased_df[['treatment']]\n",
    "X = pd.get_dummies(biased_df[['visit','recency','channel','history']],columns=['channel'],drop_first=True)#channelのダミー変数を作成。\n",
    "X = sm.add_constant(X)#定数項を入れる\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "table=results.summary().tables[1]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは\n",
    "$$\n",
    "Treatment = \\beta_{0}+ \\beta_{1}visit+ \\beta_{2}recency+ \\beta_{3}history+ \\beta_{4}channel+u\n",
    "$$\n",
    "\n",
    "という線形回帰モデルのパラメータを求めている。visitの係数は0.1509なので処置変数とvisitの間には正の相関が認められるので、一見共変量としてモデルに含めて良さそうな気がする。\n",
    "\n",
    "前回RCTのデータを用いて回帰分析した時のtreatmentの推定値は0.770だった。また、recency,history,channelの3つの共変量と処置変数treatmentでspendを回帰した結果、treatmentの係数は0.86程度になった。ここにvisitを共変量として追加して回帰すれば、treatmentの推定値はより0.770に近づく...？\n",
    "\n",
    "\n",
    "ここでの技術的なポイントは、**channelをpandasの`get_dummies()`関数を用いてダミー変数化**している点である。同じ操作は`np.where()`を使ってchannelに含まれる3つのカテゴリのうち2つをダミー変数に変換してもできる。しかし、カテゴリ数が4,5,6...と増えたとき、これで一つずつ記述しているのでは辛いので、pandasにやってもらうこの方法の方がいいのかもしれない。`get_dummies()`関数の利用はむしろ前処理の際に使える技術として覚えた方がいいのかも。\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "## visitを共変量として回帰分析をすると...？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>   -0.4057</td> <td>    0.382</td> <td>   -1.062</td> <td> 0.288</td> <td>   -1.155</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment</th>     <td>    0.2784</td> <td>    0.180</td> <td>    1.546</td> <td> 0.122</td> <td>   -0.075</td> <td>    0.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>visit</th>         <td>    7.2368</td> <td>    0.246</td> <td>   29.368</td> <td> 0.000</td> <td>    6.754</td> <td>    7.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recency</th>       <td>    0.0090</td> <td>    0.026</td> <td>    0.346</td> <td> 0.729</td> <td>   -0.042</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>history</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.316</td> <td> 0.188</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>channel_Phone</th> <td>    0.0978</td> <td>    0.306</td> <td>    0.320</td> <td> 0.749</td> <td>   -0.502</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>channel_Web</th>   <td>    0.1160</td> <td>    0.306</td> <td>    0.380</td> <td> 0.704</td> <td>   -0.483</td> <td>    0.715</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visitを含めた重回帰分析\n",
    "Y = biased_df[['spend']]\n",
    "X = pd.get_dummies(biased_df[['treatment','visit','recency','channel','history']],columns=['channel'],drop_first=True)\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "table  =results.summary().tables[1]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visitを入れて回帰した結果、treatmentのパラメータの推定値は、むしろ0.770から離れた値になっている。共変量として良さそうに見えたvisitだったが、処置の後（処置の影響を受けて？）に決まる変数であるためにPost Treatment Biasを生じさせる。\n",
    "\n",
    "結論として、**共変量として、YとZのどちらにも相関があるからといって何でもかんでも入れればいいというわけではない。**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
